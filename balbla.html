<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Asistente Virtual con IA</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .card {
            max-width: 600px;
            margin: 50px auto;
        }
        .card-body {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }
        #response {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Card para el asistente virtual -->
        <div class="card">
            <div class="card-header bg-primary text-white text-center">
                <h3>Asistente Virtual con IA</h3>
            </div>
            <div class="card-body">
                <button id="start-voice" class="btn btn-success">Iniciar Búsqueda por Voz</button>
                <div id="response"></div> <!-- Aquí se mostrará la respuesta -->
            </div>
        </div>
    </div>

    <script>
        const startButton = document.getElementById("start-voice");
        const responseDiv = document.getElementById("response");

        // Verificar si el navegador soporta la API de voz
        const recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const synth = window.speechSynthesis;

        if (!recognition) {
            alert("Tu navegador no soporta la API de reconocimiento de voz.");
        } else {
            const speechRecognition = new recognition();
            speechRecognition.lang = "es-ES";

            // Configuración de OpenAI
            const OPENAI_API_KEY = "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";

            startButton.addEventListener("click", () => {
                responseDiv.innerHTML = "Escuchando...";
                speechRecognition.start();
            });

            speechRecognition.onresult = async (event) => {
                const voiceQuery = event.results[0][0].transcript;
                responseDiv.innerHTML = `<p>Preguntaste: <strong>${voiceQuery}</strong></p>`;
                await getAIResponse(voiceQuery);
            };

            async function getAIResponse(query) {
                try {
                    const response = await fetch("https://api.openai.com/v1/chat/completions", {
                        method: "POST",
                        headers: {
                            "Content-Type": "application/json",
                            "Authorization": `Bearer ${OPENAI_API_KEY}`,
                        },
                        body: JSON.stringify({
                            model: "gpt-3.5-turbo",
                            messages: [{ role: "user", content: query }],
                        }),
                    });

                    const data = await response.json();
                    const aiResponse = data.choices[0].message.content;

                    responseDiv.innerHTML += `<p><strong>Respuesta:</strong> ${aiResponse}</p>`;

                    // Reproducir la respuesta en voz
                    const speech = new SpeechSynthesisUtterance(aiResponse);
                    speech.lang = "es-ES";
                    synth.speak(speech);
                } catch (error) {
                    responseDiv.innerHTML += `<p>Error al obtener la respuesta de la IA.</p>`;
                    console.error(error);
                }
            }
        }
    </script>
</body>
</html>
